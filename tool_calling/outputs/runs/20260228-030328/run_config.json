{
  "batch_size": 4,
  "dev_path": "tool_calling/data/formatted/dev.jsonl",
  "epochs": 5,
  "learning_rate": 0.0003,
  "lora": {
    "alpha": 32,
    "dropout": 0.05,
    "r": 16
  },
  "max_length": 384,
  "model_name": "gpt2",
  "output_root": "tool_calling/outputs/runs",
  "seed": 11711,
  "train_path": "tool_calling/data/formatted/train.jsonl",
  "use_qlora": true
}